{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DefaultAzureCredential failed to retrieve a token from the included credentials.\n",
      "Attempted credentials:\n",
      "\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\n",
      "Visit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot.this issue.\n",
      "\tManagedIdentityCredential: No token received.\n",
      "To mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am here\n"
     ]
    }
   ],
   "source": [
    "import azure.ai.ml\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "try:\n",
    "    credential =  DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/default\")\n",
    "except Exception as ex:\n",
    "    print(\"i am here\")\n",
    "    credential = InteractiveBrowserCredential()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i had to use cli credential with --no browser parameter , cause the redirect is having issues.\n",
    "\n",
    "import azure.ai.ml\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "\n",
    "credential= AzureCliCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=\"31241946-ad24-4495-85e2-31248c60d164\",\n",
    "    resource_group_name=\"ariefinternal\",\n",
    "    workspace_name=\"ariefmlworkspace\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register and upload the car dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading good_car_data.csv\u001b[32m (< 1 MB): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44.2k/44.2k [00:00<00:00, 1.69MB/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data({'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'car', 'description': 'Good Car Data', 'tags': {}, 'properties': {}, 'id': '/subscriptions/31241946-ad24-4495-85e2-31248c60d164/resourceGroups/ariefinternal/providers/Microsoft.MachineLearningServices/workspaces/ariefmlworkspace/data/car/versions/1', 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7f06a811e640>, 'serialize': <msrest.serialization.Serializer object at 0x7f06ab6cfa90>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/31241946-ad24-4495-85e2-31248c60d164/resourcegroups/ariefinternal/workspaces/ariefmlworkspace/datastores/workspaceblobstore/paths/LocalUpload/4a337dba56504a0bc17f6e0e49d1adb1/good_car_data.csv', 'referenced_uris': None})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this uploads the file from the local store to the default blob store under the default container and then LocalUpload/4*******/good_car_data.csv\n",
    "#this gibberish is a problem with the 4***\n",
    "# and the studio shows this LocalUpload/4a337dba56504a0bc17f6e0e49d1adb1/good_car_data.csv \n",
    "\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "my_path = \"abfss://amex@ariefgen2.dfs.core.windows.net/data/mlcardata\"\n",
    "car_cleaned_data = Data(\n",
    "    path=\"../../data/good_car_data.csv\",\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description=\"Good Car Data\",\n",
    "    name=\"car\",\n",
    "    version='1'\n",
    ")\n",
    "\n",
    "ml_client.data.create_or_update(car_cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data({'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'goodcardata', 'description': 'The Real car Data', 'tags': {}, 'properties': {}, 'id': '/subscriptions/31241946-ad24-4495-85e2-31248c60d164/resourceGroups/ariefinternal/providers/Microsoft.MachineLearningServices/workspaces/ariefmlworkspace/data/goodcardata/versions/1', 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7f06a818e1c0>, 'serialize': <msrest.serialization.Serializer object at 0x7f06a815e8e0>, 'version': '1', 'latest_version': None, 'path': 'abfss://amex@ariefgen2.dfs.core.windows.net/data/mlcardata/good_car_data.csv', 'referenced_uris': None})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this registers where the location is shown.\n",
    "my_path = \"abfss://amex@ariefgen2.dfs.core.windows.net/data/mlcardata/good_car_data.csv\"\n",
    "car_cleaned_data = Data(\n",
    "    path=my_path,\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description=\"The Real car Data\",\n",
    "    name=\"goodcardata\",\n",
    "    version='1'\n",
    ")\n",
    "\n",
    "ml_client.data.create_or_update(car_cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you already have a cluster named amlcluster, we will resue it\n",
      "AmlCompute with name amlcluster is created, the compute size is STANDARD_D2_V2\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "cpu_compute_target=\"amlcluster\"\n",
    "\n",
    "try:\n",
    "    cpu_cluster =  ml_client.compute.get(cpu_compute_target)\n",
    "    print(\n",
    "        f\"you already have a cluster named {cpu_compute_target}, we will resue it\"\n",
    "    )\n",
    "except Exception:\n",
    "    print(\"creating a new compute target\")\n",
    "    cpu_cluster=AmlCompute(\n",
    "        name=\"amlcluster\",\n",
    "        type=\"aml-compute\",\n",
    "        size=\"STANDARD_D2_V2\",\n",
    "        min_instances=0,\n",
    "        max_instances=2,\n",
    "        idle_time_before_scale_down=180,\n",
    "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
    "        tier=\"Dedicated\"\n",
    "        )\n",
    "    cpu_cluster=ml_client.begin_create_or_update(cpu_cluster)\n",
    "\n",
    "print(\n",
    "    f\"AmlCompute with name {cpu_cluster.name} is created, the compute size is {cpu_cluster.size}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dependencies_dir=\"../dependencies\"\n",
    "os.makedirs(dependencies_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../dependencies/conda.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {dependencies_dir}/conda.yml\n",
    "name: model-env\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.8\n",
    "  - numpy=1.21.2\n",
    "  - pip=21.2.4\n",
    "  - scipy=1.7.1\n",
    "  - scikit-learn=0.24.2\n",
    "  - pandas>=1.1,<1.2\n",
    "  - seaborn=0.11.2\n",
    "  - pip:\n",
    "    - inference-schema[numpy-support]==1.3.0\n",
    "    - xlrd==2.0.1\n",
    "    - mlflow==1.26.0\n",
    "    - azureml-mlflow==1.41.0\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "custom_env_name = \"arief-scikit-learn\"\n",
    "pipeline_job_env = Environment(\n",
    "    name=custom_env_name,\n",
    "    description=\"arief scikit learn environment\",\n",
    "    tags={\"scikit-learn\":\"0.24.2\",\"whose-environment\":\"arief_scikit_env\"},\n",
    "    conda_file=os.path.join(dependencies_dir,\"conda.yml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest\",\n",
    "    version=\"1.0.0\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Environment({'is_anonymous': False, 'auto_increment_version': False, 'name': 'arief-scikit-learn', 'description': 'arief scikit learn environment', 'tags': {'scikit-learn': '0.24.2', 'whose-environment': 'arief_scikit_env'}, 'properties': {}, 'id': None, 'base_path': './', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fdc5d1a6a30>, 'version': '1.0.0', 'latest_version': None, 'conda_file': OrderedDict([('name', 'model-env'), ('channels', ['conda-forge']), ('dependencies', ['python=3.8', 'numpy=1.21.2', 'pip=21.2.4', 'scipy=1.7.1', 'scikit-learn=0.24.2', 'pandas>=1.1,<1.2', OrderedDict([('pip', ['inference-schema[numpy-support]==1.3.0', 'xlrd==2.0.1', 'mlflow==1.26.0', 'azureml-mlflow==1.41.0'])])])]), 'image': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest', 'build': None, 'inference_config': None, 'os_type': None, 'arm_type': 'environment_version', 'conda_file_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/arbavan1/code/Users/arbavan/azure-data-science/mlin100days/carprediction/azure/dependencies/conda.yml'), 'path': None, 'upload_hash': None, 'translated_conda_file': 'name: model-env\\nchannels:\\n- conda-forge\\ndependencies:\\n- python=3.8\\n- numpy=1.21.2\\n- pip=21.2.4\\n- scipy=1.7.1\\n- scikit-learn=0.24.2\\n- pandas>=1.1,<1.2\\n- pip:\\n  - inference-schema[numpy-support]==1.3.0\\n  - xlrd==2.0.1\\n  - mlflow==1.26.0\\n  - azureml-mlflow==1.41.0\\n'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_job_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_job_env =  ml_client.environments.create_or_update(pipeline_job_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the first Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with name arief-scikit-learn is registered to workspace, the environment version is 1.0.0\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_prep_src_dir=\"../components/data_prep\"\n",
    "os.makedirs(data_prep_src_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../components/data_prep/data_prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {data_prep_src_dir}/data_prep.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import mlflow\n",
    "import seaborn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function of the script\n",
    "    got it\"\"\"\n",
    "\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
    "    parser.add_argument(\"--test_train_ratio\", type=float, help=\"split ratio\", required=False, default=0.2)\n",
    "    parser.add_argument(\"--train_data\", type=str, help=\"path to train data\")\n",
    "    parser.add_argument(\"--test_data\", type=str, help=\"path to test data\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    #start logging\n",
    "    mlflow.start_run()\n",
    "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
    "    print(\"input data:\",args.data)\n",
    "\n",
    "\n",
    "    car= pd.read_csv(args.data,header=1, index_col=0)\n",
    "    print(\"initial size data\", car.shape)\n",
    "    \n",
    "    #remove any price greater than 6000000\n",
    "    car=car[car['Price']<6000000]\n",
    "    print(\"Size after removing rows with price greater than 6000000 \", car.shape)\n",
    "\n",
    "    X=car[['name','company','year','kms_driven','fuel_type']]\n",
    "    y=car['Price']\n",
    "    #X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "    #ohe=OneHotEncoder()\n",
    "    #ohe.fit(X[['name','company','fuel_type']])\n",
    "\n",
    "    #column_trans=make_column_transformer((OneHotEncoder(categories=ohe.categories_),['name','company','fuel_type']), remainder='passthrough')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
